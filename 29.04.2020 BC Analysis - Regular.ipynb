{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn_utils.utils import SkUtilsIO,filter_by_label\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = SkUtilsIO('BC.csv').from_csv(\n",
    "    label_column='stage')\n",
    "y = ['healthy' if i == 'h' else 'bc' for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "new_y = []\n",
    "for item in y:\n",
    "    if item == \"bc\":\n",
    "        new_y.append(1)\n",
    "    else:\n",
    "        new_y.append(0)\n",
    "np_y_new = np.array(new_y)\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.read_excel('regular_analysis.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.nan_to_num(X_df), y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold test: [0.90909091 0.90909091 0.86363636 0.90909091 0.95454545 0.95454545\n",
      " 0.9047619  0.95238095 0.8        0.9       ]\n",
      "mean: 0.906\n",
      "std: 0.045\n"
     ]
    }
   ],
   "source": [
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "logreg = LogisticRegression(C=0.3e-6)\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "# logreg.fit(X_train, y_train)\n",
    "y_pred = logreg_cv.predict(X_test)\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "# scores = cross_val_score(logreg, np.nan_to_num(X_df), np_y_new, cv=kf, scoring='f1')\n",
    "log_scores = cross_val_score(logreg_cv, np.nan_to_num(X_df), np_y_new, cv=kf, scoring='f1_micro')\n",
    "print('kfold test: %s' % log_scores)\n",
    "print('mean: %s' % log_scores.mean().round(3))\n",
    "print('std: %s' % log_scores.std().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold test: [0.90909091 0.81818182 0.86363636 0.95454545 0.81818182 0.95454545\n",
      " 0.95238095 1.         0.95       1.        ]\n",
      "mean: 0.922\n",
      "std: 0.064\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=4, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "rf_scores = cross_val_score(rf, np.nan_to_num(X_df), np_y_new, cv=kf, scoring='f1_micro')\n",
    "print('kfold test: %s' % rf_scores)\n",
    "print('mean: %s' % rf_scores.mean().round(3))\n",
    "print('std: %s' % rf_scores.std().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold test: [0.63636364 0.63636364 0.63636364 0.63636364 0.63636364 0.63636364\n",
      " 0.66666667 0.66666667 0.65       0.65      ]\n",
      "mean: 0.645\n",
      "std: 0.012\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma='auto')\n",
    "svm.fit(X_train, y_train)\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "svm_scores = cross_val_score(svm, np.nan_to_num(X_df), y, cv=kf, scoring='f1_micro')\n",
    "print('kfold test: %s' % svm_scores)\n",
    "print('mean: %s' % svm_scores.mean().round(3))\n",
    "print('std: %s' % svm_scores.std().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'classifiers': ['logreg', 'rf', 'svm'], 'mean': [log_scores.mean().round(3), rf_scores.mean().round(3),svm_scores.mean().round(3)]})\n",
    "ax = df.plot.bar(x='classifiers', y='mean', rot=0)\n",
    "df.sort_values('mean', ascending=False)\n",
    "df.to_excel('regular_test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10, random_state=43)\n",
    "logreg = LogisticRegression(C=0.3e-6)\n",
    "logreg_cv_split = GridSearchCV(logreg, param_grid, cv=5)\n",
    "logreg_results = []\n",
    "for train_index, test_index in kf.split(np.nan_to_num(X_df), np_y_new):\n",
    "        X_train, y_train= np.nan_to_num(X_df)[train_index], np_y_new[train_index]\n",
    "        X_test, y_test= np.nan_to_num(X_df)[test_index], np_y_new[test_index]\n",
    "        \n",
    "        clf = logreg_cv_split.fit(X_train, y_train)\n",
    "        # print(classification_report(clf.predict(X_test), y_test))\n",
    "        logreg_results.append(classification_report(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results = []\n",
    "kf = StratifiedKFold(n_splits=10, random_state=43)\n",
    "randomforest_split = RandomForestClassifier(max_depth=4, random_state=0)\n",
    "for train_index, test_index in kf.split(np.nan_to_num(X_df), np_y_new):\n",
    "        X_train, y_train= np.nan_to_num(X_df)[train_index], np_y_new[train_index]\n",
    "        X_test, y_test= np.nan_to_num(X_df)[test_index], np_y_new[test_index]\n",
    "        \n",
    "        clf = randomforest_split.fit(X_train, y_train)\n",
    "        # print(classification_report(clf.predict(X_test), y_test))\n",
    "        rf_results.append(classification_report(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alperdokay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\alperdokay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\alperdokay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\alperdokay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\alperdokay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\alperdokay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\alperdokay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\alperdokay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\alperdokay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\alperdokay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "svm_results = []\n",
    "kf = StratifiedKFold(n_splits=10, random_state=43)\n",
    "svm_split = SVC(gamma='auto')\n",
    "for train_index, test_index in kf.split(np.nan_to_num(X_df), np_y_new):\n",
    "        X_train, y_train= np.nan_to_num(X_df)[train_index], np_y_new[train_index]\n",
    "        X_test, y_test= np.nan_to_num(X_df)[test_index], np_y_new[test_index]\n",
    "        \n",
    "        clf = svm_split.fit(X_train, y_train)\n",
    "        # print(classification_report(clf.predict(X_test), y_test))\n",
    "        svm_results.append(classification_report(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Fold Based Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88         8\n",
      "           1       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.91        22\n",
      "   macro avg       0.90      0.90      0.90        22\n",
      "weighted avg       0.91      0.91      0.91        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         6\n",
      "           1       1.00      0.88      0.93        16\n",
      "\n",
      "    accuracy                           0.91        22\n",
      "   macro avg       0.88      0.94      0.90        22\n",
      "weighted avg       0.93      0.91      0.91        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80         7\n",
      "           1       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.86        22\n",
      "   macro avg       0.84      0.86      0.85        22\n",
      "weighted avg       0.87      0.86      0.87        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         6\n",
      "           1       1.00      0.88      0.93        16\n",
      "\n",
      "    accuracy                           0.91        22\n",
      "   macro avg       0.88      0.94      0.90        22\n",
      "weighted avg       0.93      0.91      0.91        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.95        22\n",
      "   macro avg       0.94      0.97      0.95        22\n",
      "weighted avg       0.96      0.95      0.96        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94         9\n",
      "           1       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.95        22\n",
      "   macro avg       0.96      0.94      0.95        22\n",
      "weighted avg       0.96      0.95      0.95        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.90        21\n",
      "   macro avg       0.89      0.89      0.89        21\n",
      "weighted avg       0.90      0.90      0.90        21\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92         6\n",
      "           1       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.95        21\n",
      "   macro avg       0.93      0.97      0.94        21\n",
      "weighted avg       0.96      0.95      0.95        21\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.67      0.75         9\n",
      "           1       0.77      0.91      0.83        11\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.81      0.79      0.79        20\n",
      "weighted avg       0.81      0.80      0.80        20\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.89      0.89      0.89        20\n",
      "weighted avg       0.90      0.90      0.90        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in logreg_results:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Fold Based Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         6\n",
      "           1       1.00      0.88      0.93        16\n",
      "\n",
      "    accuracy                           0.91        22\n",
      "   macro avg       0.88      0.94      0.90        22\n",
      "weighted avg       0.93      0.91      0.91        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         4\n",
      "           1       1.00      0.78      0.88        18\n",
      "\n",
      "    accuracy                           0.82        22\n",
      "   macro avg       0.75      0.89      0.77        22\n",
      "weighted avg       0.91      0.82      0.84        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77         5\n",
      "           1       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.86        22\n",
      "   macro avg       0.81      0.91      0.84        22\n",
      "weighted avg       0.91      0.86      0.87        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.95        22\n",
      "   macro avg       0.94      0.97      0.95        22\n",
      "weighted avg       0.96      0.95      0.96        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         4\n",
      "           1       1.00      0.78      0.88        18\n",
      "\n",
      "    accuracy                           0.82        22\n",
      "   macro avg       0.75      0.89      0.77        22\n",
      "weighted avg       0.91      0.82      0.84        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94         9\n",
      "           1       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.95        22\n",
      "   macro avg       0.96      0.94      0.95        22\n",
      "weighted avg       0.96      0.95      0.95        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92         6\n",
      "           1       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.95        21\n",
      "   macro avg       0.93      0.97      0.94        21\n",
      "weighted avg       0.96      0.95      0.95        21\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92         6\n",
      "           1       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.93      0.96      0.94        20\n",
      "weighted avg       0.96      0.95      0.95        20\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in rf_results:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Fold Based Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.64      0.78        22\n",
      "\n",
      "    accuracy                           0.64        22\n",
      "   macro avg       0.50      0.32      0.39        22\n",
      "weighted avg       1.00      0.64      0.78        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.64      0.78        22\n",
      "\n",
      "    accuracy                           0.64        22\n",
      "   macro avg       0.50      0.32      0.39        22\n",
      "weighted avg       1.00      0.64      0.78        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.64      0.78        22\n",
      "\n",
      "    accuracy                           0.64        22\n",
      "   macro avg       0.50      0.32      0.39        22\n",
      "weighted avg       1.00      0.64      0.78        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.64      0.78        22\n",
      "\n",
      "    accuracy                           0.64        22\n",
      "   macro avg       0.50      0.32      0.39        22\n",
      "weighted avg       1.00      0.64      0.78        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.64      0.78        22\n",
      "\n",
      "    accuracy                           0.64        22\n",
      "   macro avg       0.50      0.32      0.39        22\n",
      "weighted avg       1.00      0.64      0.78        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.64      0.78        22\n",
      "\n",
      "    accuracy                           0.64        22\n",
      "   macro avg       0.50      0.32      0.39        22\n",
      "weighted avg       1.00      0.64      0.78        22\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.67      0.80        21\n",
      "\n",
      "    accuracy                           0.67        21\n",
      "   macro avg       0.50      0.33      0.40        21\n",
      "weighted avg       1.00      0.67      0.80        21\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.67      0.80        21\n",
      "\n",
      "    accuracy                           0.67        21\n",
      "   macro avg       0.50      0.33      0.40        21\n",
      "weighted avg       1.00      0.67      0.80        21\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.65      0.79        20\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.50      0.33      0.39        20\n",
      "weighted avg       1.00      0.65      0.79        20\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.65      0.79        20\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.50      0.33      0.39        20\n",
      "weighted avg       1.00      0.65      0.79        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in svm_results:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAL OVERVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifiers</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>logreg</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifiers   mean\n",
       "1          rf  0.922\n",
       "0      logreg  0.906\n",
       "2         svm  0.645"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'classifiers': ['logreg', 'rf', 'svm'], 'mean': [log_scores.mean().round(3), rf_scores.mean().round(3),svm_scores.mean().round(3)]})\n",
    "ax = df.plot.bar(x='classifiers', y='mean', rot=0)\n",
    "df.sort_values('mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from sklearn.feature_selection import VarianceThreshold, f_classif\n",
    "\n",
    "\n",
    "def variance_threshold_on_df(df: pd.DataFrame, threshold=0):\n",
    "    vt = VarianceThreshold(threshold)\n",
    "    vt.fit(df.values)\n",
    "    return df.iloc[:, vt.variances_ > threshold]\n",
    "\n",
    "def feature_importance_anova(X,\n",
    "                             y,\n",
    "                             threshold=0.001,\n",
    "                             correcting_multiple_hypotesis=True,\n",
    "                             method='fdr_bh',\n",
    "                             alpha=0.1,\n",
    "                             sort_by='F'):\n",
    "    '''\n",
    "    Provide signifance for features in dataset with anova using multiple hypostesis testing\n",
    "    :X: List of dict with key as feature names and values as features\n",
    "    :y: Labels\n",
    "    :threshold: Low-variens threshold to eliminate low varience features\n",
    "    :correcting_multiple_hypotesis: corrects p-val with multiple hypotesis testing\n",
    "    :method: method of multiple hypotesis testing\n",
    "    :alpha: alpha of multiple hypotesis testing\n",
    "    :sort_by: sorts output dataframe by pval or F\n",
    "    :return: DataFrame with F and pval for each feature with their average values \n",
    "    '''\n",
    "    df = variance_threshold_on_df(\n",
    "        pd.DataFrame.from_records(X), threshold=threshold)\n",
    "\n",
    "    F, pvals = f_classif(df.values, y)\n",
    "\n",
    "    if correcting_multiple_hypotesis:\n",
    "        _, pvals, _, _ = multipletests(pvals, alpha=alpha, method=method)\n",
    "\n",
    "    df['labels'] = y\n",
    "    df_mean = df.groupby('labels').mean().T\n",
    "\n",
    "    df_mean['F'] = F\n",
    "    df_mean['pval'] = pvals\n",
    "\n",
    "    return df_mean.sort_values(sort_by, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>labels</th>\n",
       "      <th>bc</th>\n",
       "      <th>healthy</th>\n",
       "      <th>F</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Histidine metabolism</td>\n",
       "      <td>0.101254</td>\n",
       "      <td>9.616598e-11</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.995139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Methionine and cysteine metabolism</td>\n",
       "      <td>17.285347</td>\n",
       "      <td>1.685737e+01</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.956514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fatty acid oxidation</td>\n",
       "      <td>11.769339</td>\n",
       "      <td>1.212642e+01</td>\n",
       "      <td>0.009130</td>\n",
       "      <td>0.949994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Vitamin C metabolism</td>\n",
       "      <td>0.438141</td>\n",
       "      <td>5.711981e-12</td>\n",
       "      <td>0.012948</td>\n",
       "      <td>0.948493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyaluronan metabolism</td>\n",
       "      <td>2.458166</td>\n",
       "      <td>5.437756e-11</td>\n",
       "      <td>0.019897</td>\n",
       "      <td>0.939434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tyrosine metabolism</td>\n",
       "      <td>-0.077650</td>\n",
       "      <td>2.764699e-01</td>\n",
       "      <td>0.031593</td>\n",
       "      <td>0.922263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Nucleotide salvage pathway</td>\n",
       "      <td>11.917954</td>\n",
       "      <td>5.448030e-11</td>\n",
       "      <td>0.056285</td>\n",
       "      <td>0.885475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Oxidative phosphorylation</td>\n",
       "      <td>4.519792</td>\n",
       "      <td>1.553482e-10</td>\n",
       "      <td>0.072505</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Cysteine Metabolism</td>\n",
       "      <td>116.112557</td>\n",
       "      <td>9.843016e+01</td>\n",
       "      <td>0.138866</td>\n",
       "      <td>0.797141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Vitamin B2 metabolism</td>\n",
       "      <td>3.186711</td>\n",
       "      <td>1.251101e-10</td>\n",
       "      <td>0.151478</td>\n",
       "      <td>0.795606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "labels                                      bc       healthy         F  \\\n",
       "Histidine metabolism                  0.101254  9.616598e-11  0.000037   \n",
       "Methionine and cysteine metabolism   17.285347  1.685737e+01  0.005051   \n",
       "Fatty acid oxidation                 11.769339  1.212642e+01  0.009130   \n",
       "Vitamin C metabolism                  0.438141  5.711981e-12  0.012948   \n",
       "Hyaluronan metabolism                 2.458166  5.437756e-11  0.019897   \n",
       "Tyrosine metabolism                  -0.077650  2.764699e-01  0.031593   \n",
       "Nucleotide salvage pathway           11.917954  5.448030e-11  0.056285   \n",
       "Oxidative phosphorylation             4.519792  1.553482e-10  0.072505   \n",
       "Cysteine Metabolism                 116.112557  9.843016e+01  0.138866   \n",
       "Vitamin B2 metabolism                 3.186711  1.251101e-10  0.151478   \n",
       "\n",
       "labels                                  pval  \n",
       "Histidine metabolism                0.995139  \n",
       "Methionine and cysteine metabolism  0.956514  \n",
       "Fatty acid oxidation                0.949994  \n",
       "Vitamin C metabolism                0.948493  \n",
       "Hyaluronan metabolism               0.939434  \n",
       "Tyrosine metabolism                 0.922263  \n",
       "Nucleotide salvage pathway          0.885475  \n",
       "Oxidative phosphorylation           0.871560  \n",
       "Cysteine Metabolism                 0.797141  \n",
       "Vitamin B2 metabolism               0.795606  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pathways = feature_importance_anova(X_df.fillna(0), y)\n",
    "df_pathways.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Alanine and aspartate metabolism</th>\n",
       "      <th>Alkaloid synthesis</th>\n",
       "      <th>Aminosugar metabolism</th>\n",
       "      <th>Androgen and estrogen synthesis and metabolism</th>\n",
       "      <th>Arachidonic acid metabolism</th>\n",
       "      <th>Arginine and Proline Metabolism</th>\n",
       "      <th>Bile acid synthesis</th>\n",
       "      <th>Biotin metabolism</th>\n",
       "      <th>Blood group synthesis</th>\n",
       "      <th>...</th>\n",
       "      <th>Valine, leucine, and isoleucine metabolism</th>\n",
       "      <th>Vitamin A metabolism</th>\n",
       "      <th>Vitamin B12 metabolism</th>\n",
       "      <th>Vitamin B2 metabolism</th>\n",
       "      <th>Vitamin B6 metabolism</th>\n",
       "      <th>Vitamin C metabolism</th>\n",
       "      <th>Vitamin D metabolism</th>\n",
       "      <th>Vitamin E metabolism</th>\n",
       "      <th>Xenobiotics metabolism</th>\n",
       "      <th>beta-Alanine metabolism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347.350721</td>\n",
       "      <td>-1.112827e-12</td>\n",
       "      <td>-66.583705</td>\n",
       "      <td>-0.098539</td>\n",
       "      <td>-2.321184e-12</td>\n",
       "      <td>-105.232068</td>\n",
       "      <td>-53.850349</td>\n",
       "      <td>-276.535927</td>\n",
       "      <td>8.323124e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>175.228080</td>\n",
       "      <td>47.745535</td>\n",
       "      <td>-2.345121e-12</td>\n",
       "      <td>19.888942</td>\n",
       "      <td>38.472034</td>\n",
       "      <td>-4.934211</td>\n",
       "      <td>-7.584181</td>\n",
       "      <td>-3.425183e-13</td>\n",
       "      <td>-4.829319e-12</td>\n",
       "      <td>-89.138113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>287.231674</td>\n",
       "      <td>-1.112827e-12</td>\n",
       "      <td>-2.067576</td>\n",
       "      <td>-0.098539</td>\n",
       "      <td>-2.292201e-12</td>\n",
       "      <td>-105.232068</td>\n",
       "      <td>-13.850349</td>\n",
       "      <td>556.797406</td>\n",
       "      <td>-5.194814e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>28.886616</td>\n",
       "      <td>47.745535</td>\n",
       "      <td>-2.345121e-12</td>\n",
       "      <td>19.888942</td>\n",
       "      <td>38.472034</td>\n",
       "      <td>-4.934211</td>\n",
       "      <td>-7.584181</td>\n",
       "      <td>-4.596553e-13</td>\n",
       "      <td>-5.079632e-12</td>\n",
       "      <td>-89.138113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>305.499834</td>\n",
       "      <td>-1.112827e-12</td>\n",
       "      <td>186.572694</td>\n",
       "      <td>-0.098539</td>\n",
       "      <td>9.397412e-12</td>\n",
       "      <td>48.614085</td>\n",
       "      <td>-18.713050</td>\n",
       "      <td>-276.535927</td>\n",
       "      <td>1.466358e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>248.398811</td>\n",
       "      <td>45.918394</td>\n",
       "      <td>-2.345121e-12</td>\n",
       "      <td>19.888942</td>\n",
       "      <td>38.472034</td>\n",
       "      <td>-4.934211</td>\n",
       "      <td>-7.584181</td>\n",
       "      <td>-4.599230e-13</td>\n",
       "      <td>2.930244e-11</td>\n",
       "      <td>-74.430842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>232.767388</td>\n",
       "      <td>-1.112827e-12</td>\n",
       "      <td>109.043535</td>\n",
       "      <td>-0.098539</td>\n",
       "      <td>-3.199579e-13</td>\n",
       "      <td>48.614085</td>\n",
       "      <td>1.260762</td>\n",
       "      <td>-276.535927</td>\n",
       "      <td>4.477827e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>258.851773</td>\n",
       "      <td>47.745535</td>\n",
       "      <td>-2.345121e-12</td>\n",
       "      <td>19.888942</td>\n",
       "      <td>38.472034</td>\n",
       "      <td>-4.934211</td>\n",
       "      <td>-7.584181</td>\n",
       "      <td>-4.524963e-13</td>\n",
       "      <td>-4.334149e-12</td>\n",
       "      <td>-89.138113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>326.517388</td>\n",
       "      <td>-1.112827e-12</td>\n",
       "      <td>-51.837162</td>\n",
       "      <td>-0.098539</td>\n",
       "      <td>-2.248090e-12</td>\n",
       "      <td>-105.232068</td>\n",
       "      <td>-11.907492</td>\n",
       "      <td>556.797406</td>\n",
       "      <td>1.574355e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>341.720530</td>\n",
       "      <td>47.745535</td>\n",
       "      <td>-2.345121e-12</td>\n",
       "      <td>19.888942</td>\n",
       "      <td>38.472034</td>\n",
       "      <td>-4.934211</td>\n",
       "      <td>-7.584181</td>\n",
       "      <td>-4.534094e-13</td>\n",
       "      <td>-4.360381e-12</td>\n",
       "      <td>-89.138113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>209</td>\n",
       "      <td>201.517388</td>\n",
       "      <td>-1.112827e-12</td>\n",
       "      <td>182.194398</td>\n",
       "      <td>-0.098539</td>\n",
       "      <td>-1.095660e-12</td>\n",
       "      <td>151.178188</td>\n",
       "      <td>-7.006812</td>\n",
       "      <td>556.797406</td>\n",
       "      <td>-1.178350e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>47.179299</td>\n",
       "      <td>34.232021</td>\n",
       "      <td>-2.345121e-12</td>\n",
       "      <td>19.888942</td>\n",
       "      <td>38.472034</td>\n",
       "      <td>-4.934211</td>\n",
       "      <td>-7.584181</td>\n",
       "      <td>-4.600504e-13</td>\n",
       "      <td>-5.107211e-12</td>\n",
       "      <td>-89.138113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>14.017388</td>\n",
       "      <td>-1.112827e-12</td>\n",
       "      <td>-66.583705</td>\n",
       "      <td>-0.098539</td>\n",
       "      <td>-5.376208e-13</td>\n",
       "      <td>-98.619959</td>\n",
       "      <td>13.000708</td>\n",
       "      <td>-276.535927</td>\n",
       "      <td>-5.376681e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137317</td>\n",
       "      <td>47.745535</td>\n",
       "      <td>-2.345121e-12</td>\n",
       "      <td>-56.353634</td>\n",
       "      <td>-52.437057</td>\n",
       "      <td>-4.934211</td>\n",
       "      <td>-3.723420</td>\n",
       "      <td>-1.860350e-13</td>\n",
       "      <td>-5.029315e-12</td>\n",
       "      <td>203.840596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>129.161619</td>\n",
       "      <td>-1.112827e-12</td>\n",
       "      <td>-38.335497</td>\n",
       "      <td>-0.098539</td>\n",
       "      <td>-1.135138e-12</td>\n",
       "      <td>-105.232068</td>\n",
       "      <td>3.590676</td>\n",
       "      <td>556.797406</td>\n",
       "      <td>2.047222e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>248.398811</td>\n",
       "      <td>58.894184</td>\n",
       "      <td>-2.345121e-12</td>\n",
       "      <td>-24.891278</td>\n",
       "      <td>-52.437057</td>\n",
       "      <td>-4.934211</td>\n",
       "      <td>1.036509</td>\n",
       "      <td>1.281759e-12</td>\n",
       "      <td>-1.289105e-12</td>\n",
       "      <td>37.945221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211.785245</td>\n",
       "      <td>-1.112827e-12</td>\n",
       "      <td>-49.993844</td>\n",
       "      <td>-0.098539</td>\n",
       "      <td>-2.471779e-13</td>\n",
       "      <td>151.178188</td>\n",
       "      <td>8.482984</td>\n",
       "      <td>-276.535927</td>\n",
       "      <td>-3.452931e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>53.276860</td>\n",
       "      <td>34.232021</td>\n",
       "      <td>-2.345121e-12</td>\n",
       "      <td>19.888942</td>\n",
       "      <td>38.472034</td>\n",
       "      <td>57.565789</td>\n",
       "      <td>-7.584181</td>\n",
       "      <td>5.230202e-12</td>\n",
       "      <td>5.172408e-12</td>\n",
       "      <td>160.861887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>139.017388</td>\n",
       "      <td>-1.112827e-12</td>\n",
       "      <td>-56.906286</td>\n",
       "      <td>-0.098539</td>\n",
       "      <td>-1.429210e-12</td>\n",
       "      <td>315.718229</td>\n",
       "      <td>-26.577048</td>\n",
       "      <td>-276.535927</td>\n",
       "      <td>-4.545264e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>-48.329891</td>\n",
       "      <td>47.745535</td>\n",
       "      <td>-2.345121e-12</td>\n",
       "      <td>19.888942</td>\n",
       "      <td>-52.437057</td>\n",
       "      <td>-4.934211</td>\n",
       "      <td>-7.584181</td>\n",
       "      <td>-4.534094e-13</td>\n",
       "      <td>-5.107211e-12</td>\n",
       "      <td>-89.138113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Alanine and aspartate metabolism  Alkaloid synthesis  \\\n",
       "0             0                        347.350721       -1.112827e-12   \n",
       "1             1                        287.231674       -1.112827e-12   \n",
       "2             2                        305.499834       -1.112827e-12   \n",
       "3             3                        232.767388       -1.112827e-12   \n",
       "4             4                        326.517388       -1.112827e-12   \n",
       "..          ...                               ...                 ...   \n",
       "209         209                        201.517388       -1.112827e-12   \n",
       "210         210                         14.017388       -1.112827e-12   \n",
       "211         211                        129.161619       -1.112827e-12   \n",
       "212         212                        211.785245       -1.112827e-12   \n",
       "213         213                        139.017388       -1.112827e-12   \n",
       "\n",
       "     Aminosugar metabolism  Androgen and estrogen synthesis and metabolism  \\\n",
       "0               -66.583705                                       -0.098539   \n",
       "1                -2.067576                                       -0.098539   \n",
       "2               186.572694                                       -0.098539   \n",
       "3               109.043535                                       -0.098539   \n",
       "4               -51.837162                                       -0.098539   \n",
       "..                     ...                                             ...   \n",
       "209             182.194398                                       -0.098539   \n",
       "210             -66.583705                                       -0.098539   \n",
       "211             -38.335497                                       -0.098539   \n",
       "212             -49.993844                                       -0.098539   \n",
       "213             -56.906286                                       -0.098539   \n",
       "\n",
       "     Arachidonic acid metabolism  Arginine and Proline Metabolism  \\\n",
       "0                  -2.321184e-12                      -105.232068   \n",
       "1                  -2.292201e-12                      -105.232068   \n",
       "2                   9.397412e-12                        48.614085   \n",
       "3                  -3.199579e-13                        48.614085   \n",
       "4                  -2.248090e-12                      -105.232068   \n",
       "..                           ...                              ...   \n",
       "209                -1.095660e-12                       151.178188   \n",
       "210                -5.376208e-13                       -98.619959   \n",
       "211                -1.135138e-12                      -105.232068   \n",
       "212                -2.471779e-13                       151.178188   \n",
       "213                -1.429210e-12                       315.718229   \n",
       "\n",
       "     Bile acid synthesis  Biotin metabolism  Blood group synthesis  ...  \\\n",
       "0             -53.850349        -276.535927           8.323124e-13  ...   \n",
       "1             -13.850349         556.797406          -5.194814e-12  ...   \n",
       "2             -18.713050        -276.535927           1.466358e-11  ...   \n",
       "3               1.260762        -276.535927           4.477827e-12  ...   \n",
       "4             -11.907492         556.797406           1.574355e-13  ...   \n",
       "..                   ...                ...                    ...  ...   \n",
       "209            -7.006812         556.797406          -1.178350e-12  ...   \n",
       "210            13.000708        -276.535927          -5.376681e-12  ...   \n",
       "211             3.590676         556.797406           2.047222e-11  ...   \n",
       "212             8.482984        -276.535927          -3.452931e-12  ...   \n",
       "213           -26.577048        -276.535927          -4.545264e-13  ...   \n",
       "\n",
       "     Valine, leucine, and isoleucine metabolism  Vitamin A metabolism  \\\n",
       "0                                    175.228080             47.745535   \n",
       "1                                     28.886616             47.745535   \n",
       "2                                    248.398811             45.918394   \n",
       "3                                    258.851773             47.745535   \n",
       "4                                    341.720530             47.745535   \n",
       "..                                          ...                   ...   \n",
       "209                                   47.179299             34.232021   \n",
       "210                                   -0.137317             47.745535   \n",
       "211                                  248.398811             58.894184   \n",
       "212                                   53.276860             34.232021   \n",
       "213                                  -48.329891             47.745535   \n",
       "\n",
       "     Vitamin B12 metabolism  Vitamin B2 metabolism  Vitamin B6 metabolism  \\\n",
       "0             -2.345121e-12              19.888942              38.472034   \n",
       "1             -2.345121e-12              19.888942              38.472034   \n",
       "2             -2.345121e-12              19.888942              38.472034   \n",
       "3             -2.345121e-12              19.888942              38.472034   \n",
       "4             -2.345121e-12              19.888942              38.472034   \n",
       "..                      ...                    ...                    ...   \n",
       "209           -2.345121e-12              19.888942              38.472034   \n",
       "210           -2.345121e-12             -56.353634             -52.437057   \n",
       "211           -2.345121e-12             -24.891278             -52.437057   \n",
       "212           -2.345121e-12              19.888942              38.472034   \n",
       "213           -2.345121e-12              19.888942             -52.437057   \n",
       "\n",
       "     Vitamin C metabolism  Vitamin D metabolism  Vitamin E metabolism  \\\n",
       "0               -4.934211             -7.584181         -3.425183e-13   \n",
       "1               -4.934211             -7.584181         -4.596553e-13   \n",
       "2               -4.934211             -7.584181         -4.599230e-13   \n",
       "3               -4.934211             -7.584181         -4.524963e-13   \n",
       "4               -4.934211             -7.584181         -4.534094e-13   \n",
       "..                    ...                   ...                   ...   \n",
       "209             -4.934211             -7.584181         -4.600504e-13   \n",
       "210             -4.934211             -3.723420         -1.860350e-13   \n",
       "211             -4.934211              1.036509          1.281759e-12   \n",
       "212             57.565789             -7.584181          5.230202e-12   \n",
       "213             -4.934211             -7.584181         -4.534094e-13   \n",
       "\n",
       "     Xenobiotics metabolism  beta-Alanine metabolism  \n",
       "0             -4.829319e-12               -89.138113  \n",
       "1             -5.079632e-12               -89.138113  \n",
       "2              2.930244e-11               -74.430842  \n",
       "3             -4.334149e-12               -89.138113  \n",
       "4             -4.360381e-12               -89.138113  \n",
       "..                      ...                      ...  \n",
       "209           -5.107211e-12               -89.138113  \n",
       "210           -5.029315e-12               203.840596  \n",
       "211           -1.289105e-12                37.945221  \n",
       "212            5.172408e-12               160.861887  \n",
       "213           -5.107211e-12               -89.138113  \n",
       "\n",
       "[214 rows x 92 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
